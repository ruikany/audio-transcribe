# System Overview (draft)

This api provides realtime low latency speech transcription using a hybrid microservice architecture:

- 1. Gateway service (port 8000): handles webSocket connections, VAD and produces instant with tiny.en (but lower accuracy) output for user responsiveness.
- 2. Worker service (internal): Processes finished sentences using a large-v2 faster-whisper model for high accuracy transcription.

## Connection details

General overview
Client opens a WebSocket connection. Client sends binary audio packets continuously while the user speaks. The server sends back JSON text updates asynchronously. The connection is automatically closed when the session ends.

### Input format

The server expects binary messages. Do not send text/JSON directly. Each message must be packed with a specific structure to handle audio metadata as follows:

```
// to define ws socket, replace with actual microservice server ip
let socket = new WebSocket("wss://<SERVER_IP>:8000/ws/transcribe");

function sendAudioChunk(socket, audioContext, rawInputData) { if (socket.readyState !== WebSocket.OPEN) return;

    // 1. Convert float32 audio to Int16 PCM
    let pcmData = new Int16Array(rawInputData.length);
    for (let i = 0; i < rawInputData.length; i++) {
        pcmData[i] = Math.max(-32768, Math.min(32767, rawInputData[i] * 32768));
    }

    // 2. Prepare Metadata
    let metadata = JSON.stringify({ sampleRate: audioContext.sampleRate });
    let metadataBytes = new TextEncoder().encode(metadata);

    // 3. Prepare Header (4 bytes for length)
    let header = new ArrayBuffer(4);
    new DataView(header).setInt32(0, metadataBytes.byteLength, true); // Little-endian

    // 4. Combine and Send
    let packet = new Blob([header, metadataBytes, pcmData.buffer]);
    socket.send(packet);
}
```

### Output format

The server sends back JSON messages. The client must parse these to display the transcription.

There are two types of messages:

A. Realtime Feedback / draft
Generated by the Gateway's lightweight model. These updates happen constantly while the user is speaking. They are unstable and may change.
When to use: Display this immediately to show responsiveness.
{
"type": "realtime",
"text": "hello world this is"
}

B. Full Sentence / final result
Generated by the Worker's heavy GPU model. This is sent when the server detects the user has paused (silence). This text is highly accurate and final.
When to use: Replace the "Realtime" draft with this text (e.g., in white/black text) and commit it to your conversation history.
{
"type": "fullSentence",
"text": "Hello world, this is the final transcription."
}

1.need to test latency, test with more worker replicas
2.need to change ws url to actual jetson machine
3.need to change allowed cors origin if new frontend
